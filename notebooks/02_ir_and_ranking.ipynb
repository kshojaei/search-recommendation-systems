{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Notebook 2: Information Retrieval & Ranking\n",
        "\n",
        "## Learning Objectives\n",
        "By the end of this notebook, you will be able to:\n",
        "- Define and compute TF, DF, and IDF from a small corpus\n",
        "- Build TF–IDF vectors and rank documents using cosine similarity\n",
        "- Explain and implement BM25 ranking, and compare it to TF–IDF\n",
        "- Run hands-on experiments to see how tokenization and parameters affect ranking\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Outline\n",
        "1. Setup and toy corpus\n",
        "2. Tokenization and vocabulary\n",
        "3. TF, DF, IDF\n",
        "4. TF–IDF vectors and cosine similarity\n",
        "5. BM25 ranking\n",
        "6. TF–IDF vs BM25: comparisons\n",
        "7. Hands-on exercises\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import math \n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "\n",
        "docs = [\n",
        "    {\"id\": \"D1\", \"text\": \"iphone 14 pro smartphone apple camera\"},\n",
        "    {\"id\": \"D2\", \"text\": \"samsung galaxy smartphone android camera\"},\n",
        "    {\"id\": \"D3\", \"text\": \"nike running shoes comfort\"},\n",
        "    {\"id\": \"D4\", \"text\": \"adidas running shoes boost\"},\n",
        "    {\"id\": \"D5\", \"text\": \"macbook pro laptop apple\"}, ]\n",
        "\n",
        "def tokenizer(text):\n",
        "    return [t for t in str(text).lower().repalce('-', ' ').split() if t]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>D1</td>\n",
              "      <td>[iphone, 14, pro, smartphone, apple, camera]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>D2</td>\n",
              "      <td>[samsung, galaxy, smartphone, android, camera]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>D3</td>\n",
              "      <td>[nike, running, shoes, comfort]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>D4</td>\n",
              "      <td>[adidas, running, shoes, boost]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>D5</td>\n",
              "      <td>[macbook, pro, laptop, apple]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id                                          tokens\n",
              "0  D1    [iphone, 14, pro, smartphone, apple, camera]\n",
              "1  D2  [samsung, galaxy, smartphone, android, camera]\n",
              "2  D3                 [nike, running, shoes, comfort]\n",
              "3  D4                 [adidas, running, shoes, boost]\n",
              "4  D5                   [macbook, pro, laptop, apple]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Tiny corpus: product-like docs\n",
        "docs = [\n",
        "    {\"id\": \"D1\", \"text\": \"iphone 14 pro smartphone apple camera\"},\n",
        "    {\"id\": \"D2\", \"text\": \"samsung galaxy smartphone android camera\"},\n",
        "    {\"id\": \"D3\", \"text\": \"nike running shoes comfort\"},\n",
        "    {\"id\": \"D4\", \"text\": \"adidas running shoes boost\"},\n",
        "    {\"id\": \"D5\", \"text\": \"macbook pro laptop apple\"},\n",
        "]\n",
        "\n",
        "def tokenize(text: str):\n",
        "    return [t for t in str(text).lower().replace('-', ' ').split() if t]\n",
        "\n",
        "corpus_tokens = [tokenize(d[\"text\"]) for d in docs]\n",
        "corpus_df = pd.DataFrame({\"id\": [d[\"id\"] for d in docs], \"tokens\": corpus_tokens})\n",
        "corpus_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vocabulary and frequencies\n",
        "from collections import Counter, defaultdict\n",
        "\n",
        "vocab = sorted({t for tokens in corpus_tokens for t in tokens})\n",
        "N = len(corpus_tokens)\n",
        "\n",
        "doc_term_counts = [Counter(tokens) for tokens in corpus_tokens]\n",
        "df_counts = Counter(t for tokens in corpus_tokens for t in set(tokens))\n",
        "\n",
        "print(\"Vocab:\", vocab)\n",
        "print(\"Docs:\", N)\n",
        "print(\"DF counts:\", dict(df_counts))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## TF, DF, IDF (formulas)\n",
        "\n",
        "- Term Frequency (TF): count in a document (or normalized variant)\n",
        "- Document Frequency (DF): number of documents containing the term\n",
        "- Inverse Document Frequency (IDF):\n",
        "\n",
        "$$\\mathrm{IDF}(t) = \\log\\frac{N}{\\mathrm{DF}(t)}$$\n",
        "\n",
        "(We use natural log here; base choice only scales values.)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute IDF and TF-IDF vectors\n",
        "idf = {t: math.log(N / df_counts[t]) for t in vocab}\n",
        "\n",
        "# Build dense TF-IDF vectors in vocab order\n",
        "def tfidf_vector(term_counts: Counter):\n",
        "    return np.array([term_counts.get(t, 0) * idf[t] for t in vocab], dtype=float)\n",
        "\n",
        "doc_vectors = [tfidf_vector(tc) for tc in doc_term_counts]\n",
        "\n",
        "# Cosine similarity\n",
        "def cosine(a: np.ndarray, b: np.ndarray):\n",
        "    na = np.linalg.norm(a)\n",
        "    nb = np.linalg.norm(b)\n",
        "    if na == 0 or nb == 0:\n",
        "        return 0.0\n",
        "    return float(np.dot(a, b) / (na * nb))\n",
        "\n",
        "# Build a query vector and rank\n",
        "def rank_tfidf(query: str, top_k: int = 5):\n",
        "    q_tokens = tokenize(query)\n",
        "    q_counts = Counter(q_tokens)\n",
        "    q_vec = tfidf_vector(q_counts)\n",
        "    scores = []\n",
        "    for doc, vec in zip(docs, doc_vectors):\n",
        "        scores.append((doc[\"id\"], cosine(q_vec, vec)))\n",
        "    scores.sort(key=lambda x: x[1], reverse=True)\n",
        "    return scores[:top_k]\n",
        "\n",
        "print(\"TF-IDF ranking for 'running shoes':\", rank_tfidf(\"running shoes\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## BM25 (formulas and intuition)\n",
        "\n",
        "- Document length matters: longer docs naturally have more term hits; BM25 normalizes by length.\n",
        "- Core scoring for a term t:\n",
        "\n",
        "$$\\mathrm{BM25}(t) = \\mathrm{IDF}(t) \\cdot \\frac{tf \\cdot (k_1 + 1)}{tf + k_1\\cdot(1 - b + b\\cdot\\frac{len}{avglen})}$$\n",
        "\n",
        "Where:\n",
        "- tf: term frequency in this document\n",
        "- len: document length (token count)\n",
        "- avglen: average doc length in the corpus\n",
        "- k1: term saturation (typ. 1.2-2.0)\n",
        "- b: length normalization (typ. 0.6-0.9)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Implement BM25 ranking\n",
        "avg_len = float(np.mean([len(toks) for toks in corpus_tokens]))\n",
        "len_by_doc = {d[\"id\"]: len(toks) for d, toks in zip(docs, corpus_tokens)}\n",
        "\n",
        "# IDF variant used in BM25 (Okapi): add 0.5 smoothing to avoid negative/infinite values\n",
        "bm25_idf = {}\n",
        "for t in vocab:\n",
        "    df = df_counts[t]\n",
        "    bm25_idf[t] = math.log((N - df + 0.5) / (df + 0.5) + 1)\n",
        "\n",
        "\n",
        "def bm25_score(query: str, k1: float = 1.5, b: float = 0.75):\n",
        "    q_tokens = tokenize(query)\n",
        "    q_counts = Counter(q_tokens)\n",
        "    scores = {d[\"id\"]: 0.0 for d in docs}\n",
        "    for d, term_counts in zip(docs, doc_term_counts):\n",
        "        Ld = len_by_doc[d[\"id\"]]\n",
        "        for t, qtf in q_counts.items():\n",
        "            tf = term_counts.get(t, 0)\n",
        "            if tf == 0:\n",
        "                continue\n",
        "            denom = tf + k1 * (1 - b + b * (Ld / avg_len))\n",
        "            s = bm25_idf[t] * ((tf * (k1 + 1)) / denom)\n",
        "            scores[d[\"id\"]] += s\n",
        "    ranked = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    return ranked\n",
        "\n",
        "print(\"BM25 ranking for 'running shoes':\", bm25_score(\"running shoes\")[:5])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare TF-IDF vs BM25 on a few queries\n",
        "queries = [\"iphone camera\", \"running shoes\", \"apple laptop\", \"android smartphone\"]\n",
        "\n",
        "for q in queries:\n",
        "    tfidf_top = rank_tfidf(q)\n",
        "    bm25_top = bm25_score(q)\n",
        "    print(f\"\\nQuery: {q}\")\n",
        "    print(\"TF-IDF:\", tfidf_top[:3])\n",
        "    print(\"BM25  :\", bm25_top[:3])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Learning-to-Rank: Pointwise vs Pairwise vs Listwise (interview-ready)\n",
        "\n",
        "- Pointwise: predict an absolute relevance score per (query, doc). Loss: regression or classification.\n",
        "- Pairwise: learn preferences between doc pairs for the same query (d+ should rank above d−). Loss: pairwise logistic (RankNet), hinge.\n",
        "- Listwise: optimize a list-level objective (e.g., soft-NDCG, ListNet/ListMLE, LambdaRank/LambdaMART).\n",
        "\n",
        "Why pairwise?\n",
        "- Directly models relative preferences; robust when absolute labels are noisy.\n",
        "- Aligns with click-derived training data where we know clicked > non-clicked.\n",
        "- Often simpler than listwise and captures ordering better than pointwise.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pairwise demo: learn to prefer clicked docs using simple features\n",
        "from itertools import combinations\n",
        "from collections import defaultdict\n",
        "\n",
        "# Create tiny synthetic click labels (for interview-style demo)\n",
        "# Format: clicks[query][doc_id] = 1 if clicked else 0\n",
        "clicks = defaultdict(dict)\n",
        "clicks['running shoes']['D3'] = 1  # nike\n",
        "clicks['running shoes']['D4'] = 1  # adidas\n",
        "clicks['running shoes']['D1'] = 0\n",
        "clicks['running shoes']['D2'] = 0\n",
        "clicks['running shoes']['D5'] = 0\n",
        "\n",
        "# Feature function: combine BM25 and TF-IDF cosine as two features\n",
        "\n",
        "def features(query: str, doc_id: str):\n",
        "    # TF-IDF cosine\n",
        "    tfidf_score = dict(rank_tfidf(query)).get(doc_id, 0.0)\n",
        "    # BM25 score\n",
        "    bm25_score_map = dict(bm25_score(query))\n",
        "    bm25_val = bm25_score_map.get(doc_id, 0.0)\n",
        "    return np.array([tfidf_score, bm25_val], dtype=float)\n",
        "\n",
        "# Build pairwise training data (d+ vs d- for same query)\n",
        "X = []\n",
        "y = []\n",
        "for q, labels in clicks.items():\n",
        "    pos = [d for d, lbl in labels.items() if lbl == 1]\n",
        "    neg = [d for d, lbl in labels.items() if lbl == 0]\n",
        "    for d_pos in pos:\n",
        "        for d_neg in neg:\n",
        "            # Positive direction: d_pos should outrank d_neg -> label 1\n",
        "            X.append(features(q, d_pos) - features(q, d_neg))\n",
        "            y.append(1)\n",
        "            # Negative direction: d_neg should not outrank d_pos -> label 0\n",
        "            X.append(features(q, d_neg) - features(q, d_pos))\n",
        "            y.append(0)\n",
        "\n",
        "X = np.vstack(X) if X else np.zeros((0, 2))\n",
        "y = np.array(y) if y else np.zeros((0,), dtype=int)\n",
        "\n",
        "# Pairwise logistic regression (RankNet-style on feature differences)\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "clf = None\n",
        "if len(np.unique(y)) >= 2:\n",
        "    clf = LogisticRegression(solver='lbfgs')\n",
        "    clf.fit(X, y)\n",
        "    print(\"Pairwise weights (tfidf, bm25):\", clf.coef_[0])\n",
        "else:\n",
        "    print(\"[Note] Not enough class variety for pairwise training; falling back to BM25-only ranking.\")\n",
        "\n",
        "# Inference: score docs with learned weights and rank\n",
        "\n",
        "def pairwise_rank(query: str):\n",
        "    # Fallback to BM25 if model not trained\n",
        "    if clf is None:\n",
        "        return bm25_score(query)\n",
        "    scores = []\n",
        "    w = clf.coef_[0]\n",
        "    for d in docs:\n",
        "        f = features(query, d['id'])\n",
        "        scores.append((d['id'], float(np.dot(w, f))))\n",
        "    scores.sort(key=lambda x: x[1], reverse=True)\n",
        "    return scores\n",
        "\n",
        "print(\"\\nPairwise model ranking for 'running shoes':\", pairwise_rank('running shoes')[:5])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build synthetic pointwise CTR dataset and train LogisticRegression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score, log_loss\n",
        "\n",
        "pointwise_clicks = {\n",
        "    'running shoes': {'D3': 1, 'D4': 1, 'D1': 0, 'D2': 0, 'D5': 0},\n",
        "    'iphone camera': {'D1': 1, 'D2': 0, 'D3': 0, 'D4': 0, 'D5': 0},\n",
        "    'apple laptop': {'D5': 1, 'D1': 1, 'D2': 0, 'D3': 0, 'D4': 0},\n",
        "}\n",
        "\n",
        "# Feature builder reused\n",
        "\n",
        "def build_pointwise_dataset(clicks_dict):\n",
        "    rows = []\n",
        "    for q, label_map in clicks_dict.items():\n",
        "        tfidf_map = dict(rank_tfidf(q))\n",
        "        bm25_map = dict(bm25_score(q))\n",
        "        for doc in docs:\n",
        "            d = doc['id']\n",
        "            if d not in label_map:\n",
        "                continue\n",
        "            x = {\n",
        "                'query': q,\n",
        "                'doc': d,\n",
        "                'tfidf': tfidf_map.get(d, 0.0),\n",
        "                'bm25': bm25_map.get(d, 0.0),\n",
        "                'len': len_by_doc[d] / avg_len,\n",
        "                'y': label_map[d]\n",
        "            }\n",
        "            rows.append(x)\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "ctr_df = build_pointwise_dataset(pointwise_clicks)\n",
        "X = ctr_df[['tfidf','bm25','len']].values\n",
        "y = np.asarray(ctr_df['y'].values, dtype=int)\n",
        "\n",
        "# Ensure both classes exist\n",
        "if len(np.unique(y)) < 2:\n",
        "    raise ValueError(\"Pointwise labels must contain both 0 and 1 for AUC/LogLoss.\")\n",
        "\n",
        "ctr_clf = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
        "ctr_clf.fit(X, y)\n",
        "probs = ctr_clf.predict_proba(X)[:,1]\n",
        "\n",
        "print(\"AUC:\", f\"{roc_auc_score(y, probs):.3f}\")\n",
        "print(\"LogLoss:\", f\"{log_loss(y, probs):.3f}\")\n",
        "\n",
        "# Per-query NDCG@3 using predicted CTR as ranking score\n",
        "\n",
        "def dcg_at_k_labels(labels, k):\n",
        "    dcg = 0.0\n",
        "    for i, rel in enumerate(labels[:k]):\n",
        "        dcg += (2**rel - 1) / math.log2(i + 2)\n",
        "    return dcg\n",
        "\n",
        "def ndcg_at_k_from_pred(df, k=3):\n",
        "    ndcgs = []\n",
        "    for q, group in df.groupby('query'):\n",
        "        g = group.copy()\n",
        "        g = g.assign(pred=ctr_clf.predict_proba(g[['tfidf','bm25','len']].values)[:,1])\n",
        "        g_sorted = g.sort_values('pred', ascending=False)\n",
        "        rel_sorted = g_sorted['y'].tolist()\n",
        "        dcg = dcg_at_k_labels(rel_sorted, k)\n",
        "        ideal = sorted(g['y'].tolist(), reverse=True)\n",
        "        idcg = dcg_at_k_labels(ideal, k)\n",
        "        ndcg = dcg / idcg if idcg > 0 else 0.0\n",
        "        ndcgs.append((q, ndcg))\n",
        "    return ndcgs\n",
        "\n",
        "nd = ndcg_at_k_from_pred(ctr_df, k=3)\n",
        "print(\"Per-query NDCG@3:\")\n",
        "for q, v in nd:\n",
        "    print(f\"  {q}: {v:.3f}\")\n",
        "print(\"Avg NDCG@3:\", f\"{np.mean([v for _, v in nd]):.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercises (Pairwise)\n",
        "- Replace synthetic clicks with your own tiny labels; retrain and observe weight changes.\n",
        "- Add a new feature (e.g., title exact-match flag) into `features()`; measure improvement.\n",
        "- Stress test: make one doc much longer; compare TF-IDF vs BM25 vs pairwise ranking.\n",
        "- Interview prompt: explain why pairwise training can learn to combine TF-IDF and BM25 better than either alone.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Interview cheat sheet (IR & Ranking)\n",
        "\n",
        "- BM25 intuition: term saturation (k1) prevents overcounting frequent terms; length norm (b) reduces bias for long docs; IDF down-weights common terms.\n",
        "- TF‑IDF vs BM25: TF‑IDF is linear in TF and ignores document length; BM25 handles saturation and length, usually better for search.\n",
        "- Learning‑to‑rank:\n",
        "  - Pointwise: simple, but fits absolute labels; can misalign with ordering.\n",
        "  - Pairwise: optimizes relative preferences; robust with click data.\n",
        "  - Listwise: best alignment with ranking metrics (NDCG), more complex to train.\n",
        "- Feature ideas: exact/phrase match, field boosts (title > description), popularity/freshness, price bands, brand match, clickthrough priors.\n",
        "- Metric selection: use NDCG@K for overall ranking quality; MRR/Precision@K for navigational; Recall@K for discovery/coverage; always pair with online guardrails (CTR, Conversion, RPS, latency, zero‑results).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
