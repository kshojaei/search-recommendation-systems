{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Introduction to Search Systems\n",
        "\n",
        "## Learning Objectives\n",
        "By the end of this notebook, you will be able to:\n",
        "- Understand what a search system is and why it matters in e-commerce\n",
        "- Identify the key components: query processing, indexing, retrieval, ranking, presentation\n",
        "- Build and play with simple search functions over a toy product catalog\n",
        "- Evaluate search quality with precision@K, recall@K, MRR, and NDCG (with formulas)\n",
        "- Organize your code into a reusable `SimpleSearchSystem` class\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Key Components of a Search System\n",
        "\n",
        "1. Query Processing: tokenization, normalization, synonyms/typo handling\n",
        "2. Indexing: build inverted index for fast lookup\n",
        "3. Retrieval: collect candidate documents matching query terms\n",
        "4. Ranking: score candidates (e.g., TF-IDF) and order by relevance\n",
        "5. Presentation: facets, filters, suggestions, UI formatting\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample product Data (1 row):\n",
            "================================================================================\n",
            "                                                        0\n",
            "id                                                   P001\n",
            "title                                       iPhone 14 Pro\n",
            "description  Latest Apple smartphone with advanced camera\n",
            "category                                      Electronics\n",
            "price                                              999.99\n",
            "brand                                               Apple\n",
            "\n",
            "Dataset Shape: (8, 6)\n",
            "Categories: ['Electronics' 'Shoes' 'Clothing']\n",
            "Brands: ['Apple' 'Samsung' 'Nike' 'Adidas' 'Dell' 'Fashion Brand' 'Denim Co']\n",
            "Price Range: $59.99 - $2499.99\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Sample product data (tiny catalog for fast iteration)\n",
        "products_data = [\n",
        "    (\"P001\", \"iPhone 14 Pro\", \"Latest Apple smartphone with advanced camera\", \"Electronics\", 999.99, \"Apple\"),\n",
        "    (\"P002\", \"Samsung Galaxy S23\", \"Android smartphone with great camera\", \"Electronics\", 799.99, \"Samsung\"),\n",
        "    (\"P003\", \"Nike Air Max\", \"Comfortable running shoes\", \"Shoes\", 129.99, \"Nike\"),\n",
        "    (\"P004\", \"Adidas Ultraboost\", \"Premium running shoes\", \"Shoes\", 180.00, \"Adidas\"),\n",
        "    (\"P005\", \"MacBook Pro 16\", \"Professional laptop for work\", \"Electronics\", 2499.99, \"Apple\"),\n",
        "    (\"P006\", \"Dell XPS 13\", \"Ultrabook laptop\", \"Electronics\", 1199.99, \"Dell\"),\n",
        "    (\"P007\", \"Red Dress\", \"Elegant evening dress\", \"Clothing\", 89.99, \"Fashion Brand\"),\n",
        "    (\"P008\", \"Blue Jeans\", \"Classic denim jeans\", \"Clothing\", 59.99, \"Denim Co\"),\n",
        "]\n",
        "\n",
        "df_products = pd.DataFrame(products_data, columns=[\"id\",\"title\",\"description\",\"category\",\"price\",\"brand\"])\n",
        "print(\"Sample product Data (1 row):\")\n",
        "print(\"=\"*80)\n",
        "print(df_products.head(1).T)\n",
        "print(f\"\\nDataset Shape: {df_products.shape}\")\n",
        "print(f\"Categories: {df_products.category.unique()}\")\n",
        "print(f\"Brands: {df_products.brand.unique()}\")\n",
        "print(f\"Price Range: ${df_products.price.min():.2f} - ${df_products.price.max():.2f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Find all Apple products:\n",
            "            title  brand\n",
            "0   iPhone 14 Pro  Apple\n",
            "4  MacBook Pro 16  Apple\n",
            "\n",
            "Find all products under $200:\n",
            "               title   price\n",
            "2       Nike Air Max  129.99\n",
            "3  Adidas Ultraboost  180.00\n",
            "6          Red Dress   89.99\n",
            "7         Blue Jeans   59.99\n"
          ]
        }
      ],
      "source": [
        "# Quick data exploration examples\n",
        "print(\"\\nFind all Apple products:\")\n",
        "print(df_products[df_products.brand == \"Apple\"][['title','brand']])\n",
        "\n",
        "print(\"\\nFind all products under $200:\")\n",
        "print(df_products[df_products.price < 200][['title','price']])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing simple search for \"iPhone\":\n",
            "1. iPhone 14 Pro - $999.99 (Score: 2)\n"
          ]
        }
      ],
      "source": [
        "# Simple lexical search (playground)\n",
        "def simple_search(products_df: pd.DataFrame, query: str):\n",
        "    query_lower = str(query).lower()\n",
        "    results = []\n",
        "    for _, row in products_df.iterrows():\n",
        "        title_match = query_lower in str(row['title']).lower()\n",
        "        desc_match = query_lower in str(row['description']).lower()\n",
        "        if title_match or desc_match:\n",
        "            score = 2 if title_match else 1\n",
        "            if desc_match:\n",
        "                score += 1\n",
        "            results.append({'product': row.to_dict(), 'score': score})\n",
        "    results.sort(key=lambda x: x['score'], reverse=True)\n",
        "    return results\n",
        "\n",
        "print('Testing simple search for \"iPhone\":')\n",
        "for i, r in enumerate(simple_search(df_products, 'iPhone'), 1):\n",
        "    p = r['product']\n",
        "    print(f\"{i}. {p['title']} - ${p['price']} (Score: {r['score']})\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing improved search for 'running shoes':\n",
            "1. Nike Air Max - $129.99 (Score: 2, Matches: 2)\n",
            "2. Adidas Ultraboost - $180.0 (Score: 2, Matches: 2)\n"
          ]
        }
      ],
      "source": [
        "# Improved search with tokenization and multi-term matching\n",
        "def tokenize_text(text: str):\n",
        "    punctuation_chars = \".,!?;:()[]{}'\\\"-\"\n",
        "    text = text.lower()\n",
        "    for ch in punctuation_chars:\n",
        "        text = text.replace(ch, ' ')\n",
        "    return [w for w in text.split() if w]\n",
        "\n",
        "def improved_search(products_df: pd.DataFrame, query: str):\n",
        "    query_tokens = tokenize_text(query)\n",
        "    results = []\n",
        "    for _, row in products_df.iterrows():\n",
        "        searchable_tokens = tokenize_text(f\"{row['title']} {row['description']}\")\n",
        "        matches = sum(1 for t in query_tokens if t in searchable_tokens)\n",
        "        if matches > 0:\n",
        "            score = matches + (1 if any(t in row['title'].lower() for t in query_tokens) else 0)\n",
        "            results.append({'product': row.to_dict(), 'score': score, 'matches': matches})\n",
        "    results.sort(key=lambda x: x['score'], reverse=True)\n",
        "    return results\n",
        "\n",
        "print(\"Testing improved search for 'running shoes':\")\n",
        "for i, r in enumerate(improved_search(df_products, 'running shoes'), 1):\n",
        "    p = r['product']\n",
        "    print(f\"{i}. {p['title']} - ${p['price']} (Score: {r['score']}, Matches: {r['matches']})\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## How to choose the right evaluation metric (and why)\n",
        "\n",
        "- Precision@K\n",
        "  - What it measures: fraction of top-K results that are relevant\n",
        "  - When it matters most: navigational/transactional queries where users expect high-quality results at the very top (e.g., brand, SKU, \"iPhone 14 Pro\")\n",
        "  - Trade‑off: Raising precision can reduce recall if you return fewer diverse results\n",
        "\n",
        "- Recall@K\n",
        "  - What it measures: fraction of all relevant items that appear in the top K\n",
        "  - When it matters most: exploratory/browse queries, long-tail attributes, when users might scroll or filter to find more options (e.g., \"running shoes\")\n",
        "  - Trade‑off: Raising recall can lower precision by including more borderline results\n",
        "\n",
        "- MAP (Mean Average Precision)\n",
        "  - What it measures: average precision across ranks for each query, then averaged across queries\n",
        "  - Why it’s useful: rewards ranking all relevant items high (not just the first one); stable across queries with multiple relevant items\n",
        "  - When to prefer: offline relevance benchmarking with multiple relevant items per query\n",
        "\n",
        "- MRR (Mean Reciprocal Rank)\n",
        "  - What it measures: how quickly (at which rank) the first relevant item appears\n",
        "  - Why it’s useful: simple, focused on the first hit; excellent for navigational queries (e.g., user wants a specific product)\n",
        "  - When to prefer: scenarios where “first correct result fast” matters (e.g., product detail lookup)\n",
        "\n",
        "- NDCG (Normalized Discounted Cumulative Gain)\n",
        "  - What it measures: graded relevance with position discounting; rewards highly relevant results at the top\n",
        "  - Why it’s useful: captures both relevance intensity and rank position; robust to multiple relevance levels\n",
        "  - When to prefer: realistic ranking tasks with graded labels (e.g., “perfect”, “good”, “ok”); especially in e‑commerce where not all relevant items are equal\n",
        "\n",
        "- Putting it together for e‑commerce\n",
        "  - Checkout-focused searches (e.g., brand/SKU): prioritize MRR/Precision@K (K in [1,3])\n",
        "  - Browse/discovery (e.g., “black running shoes”): prioritize Recall@K and NDCG@K (K in [10,20])\n",
        "  - Overall offline evaluation: use NDCG@K and MAP for robustness; report Precision/Recall for interpretability\n",
        "  - Online A/B guardrails: CTR, Add‑to‑Cart, Conversion Rate, Revenue/Search, plus Zero‑Results Rate and latency (p95/p99)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluation Metrics:\n",
        "\n",
        "- Precision@K: Of the top K results, what fraction are relevant?\n",
        "\n",
        "$$\\mathrm{P@K} = \\frac{\\lvert\\text{Relevant in top K}\\rvert}{K}$$\n",
        "\n",
        "- Recall@K: Of all relevant items, how many did we retrieve in top K?\n",
        "\n",
        "$$\\mathrm{R@K} = \\frac{\\lvert\\text{Relevant in top K}\\rvert}{\\lvert\\text{Total relevant}\\rvert}$$\n",
        "\n",
        "- Reciprocal Rank for a query (0 if none):\n",
        "\n",
        "$$\\mathrm{RR} = \\frac{1}{\\text{rank of first relevant}}$$\n",
        "\n",
        "- Mean Reciprocal Rank over queries Q:\n",
        "\n",
        "$$\\mathrm{MRR} = \\frac{1}{\\lvert Q \\rvert} \\sum_{q \\in Q} \\mathrm{RR}_q$$\n",
        "\n",
        "- Discounted Cumulative Gain@K (graded relevance r_i):\n",
        "\n",
        "$$\\mathrm{DCG@K} = \\sum_{i=1}^{K} \\frac{2^{r_i}-1}{\\log_2(i+1)}$$\n",
        "\n",
        "- Normalized DCG@K:\n",
        "\n",
        "$$\\mathrm{NDCG@K} = \\frac{\\mathrm{DCG@K}}{\\mathrm{IDCG@K}}$$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "iPhone: P@1=1.000, R@1=1.000\n",
            "iPhone: P@2=1.000, R@2=1.000\n",
            "iPhone: P@3=1.000, R@3=1.000\n"
          ]
        }
      ],
      "source": [
        "# Inline metric helpers (binary relevance)\n",
        "\n",
        "def precision_at_k(relevant_items, retrieved_items, k: int) -> float:\n",
        "    if k == 0 or not retrieved_items:\n",
        "        return 0.0\n",
        "    top_k = set(retrieved_items[:k])\n",
        "    rel = set(relevant_items)\n",
        "    return len(top_k & rel) / min(k, len(retrieved_items))\n",
        "\n",
        "\n",
        "def recall_at_k(relevant_items, retrieved_items, k: int) -> float:\n",
        "    rel = set(relevant_items)\n",
        "    if not rel:\n",
        "        return 0.0\n",
        "    top_k = set(retrieved_items[:k])\n",
        "    return len(top_k & rel) / len(rel)\n",
        "\n",
        "query_relevance = {\n",
        "    'iPhone': {'P001'},\n",
        "    'laptop': {'P005','P006'},\n",
        "    'shoes': {'P003','P004'},\n",
        "}\n",
        "\n",
        "q = 'iPhone'\n",
        "ret = [r['product']['id'] for r in improved_search(df_products, q)]\n",
        "rel = query_relevance[q]\n",
        "\n",
        "for k in [1,2,3]:\n",
        "    p = precision_at_k(rel, ret, k)\n",
        "    r = recall_at_k(rel, ret, k)\n",
        "    print(f\"{q}: P@{k}={p:.3f}, R@{k}={r:.3f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MRR over ['iPhone', 'laptop', 'shoes']: 1.000\n"
          ]
        }
      ],
      "source": [
        "# MRR across multiple queries (binary relevance)\n",
        "def reciprocal_rank_for_query(relevant_ids, retrieved_ids):\n",
        "    relevant = set(relevant_ids)\n",
        "    for idx, pid in enumerate(retrieved_ids, start=1):\n",
        "        if pid in relevant:\n",
        "            return 1.0/idx\n",
        "    return 0.0\n",
        "\n",
        "queries = ['iPhone','laptop','shoes']\n",
        "rrs = []\n",
        "for q in queries:\n",
        "    ret = [r['product']['id'] for r in improved_search(df_products, q)]\n",
        "    rel = query_relevance[q]\n",
        "    rrs.append(reciprocal_rank_for_query(rel, ret))\n",
        "\n",
        "mrr = float(np.mean(rrs)) if rrs else 0.0\n",
        "print(f\"MRR over {queries}: {mrr:.3f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DCG@1=3.000, NDCG@1=1.000\n",
            "DCG@3=3.500, NDCG@3=0.649\n",
            "DCG@5=4.661, NDCG@5=0.864\n"
          ]
        }
      ],
      "source": [
        "# Graded relevance NDCG demo (keeps intuition clear)\n",
        "\n",
        "def dcg_at_k(relevance_scores, k):\n",
        "    dcg = 0.0\n",
        "    for i in range(min(k, len(relevance_scores))):\n",
        "        dcg += (2**relevance_scores[i] - 1) / np.log2(i + 2)\n",
        "    return dcg\n",
        "\n",
        "def ndcg_at_k(relevance_scores, k):\n",
        "    dcg = dcg_at_k(relevance_scores, k)\n",
        "    ideal = sorted(relevance_scores, reverse=True)\n",
        "    idcg = dcg_at_k(ideal, k)\n",
        "    return dcg / idcg if idcg > 0 else 0.0\n",
        "\n",
        "scores = [2,0,1,0,2]\n",
        "for k in [1,3,5]:\n",
        "    print(f\"DCG@{k}={dcg_at_k(scores,k):.3f}, NDCG@{k}={ndcg_at_k(scores,k):.3f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Organizing Code with a Class\n",
        "Benefits: encapsulation, reusability, maintainability. We'll expose a clean `search()` and reuse earlier tokenization and scoring ideas.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'query': 'iPhone', 'retrieved': ['P001'], 'relevant': ['P001'], 'precision@3': 1.0, 'recall@3': 1.0}\n",
            "{'query': 'laptop', 'retrieved': ['P005', 'P006'], 'relevant': ['P005', 'P006'], 'precision@3': 1.0, 'recall@3': 1.0}\n",
            "{'query': 'shoes', 'retrieved': ['P003', 'P004'], 'relevant': ['P004', 'P003'], 'precision@3': 1.0, 'recall@3': 1.0}\n"
          ]
        }
      ],
      "source": [
        "class SimpleSearchSystem:\n",
        "    def __init__(self, products_df: pd.DataFrame):\n",
        "        self.products_df = products_df\n",
        "        self.query_relevance = {\n",
        "            'iPhone': {'P001'},\n",
        "            'laptop': {'P005','P006'},\n",
        "            'shoes': {'P003','P004'},\n",
        "        }\n",
        "    def tokenize_text(self, text: str):\n",
        "        punctuation_chars = \".,!?;:()[]{}'\\\"-\"\n",
        "        text = str(text).lower()\n",
        "        for ch in punctuation_chars:\n",
        "            text = text.replace(ch, ' ')\n",
        "        return [w for w in text.split() if w]\n",
        "    def search(self, query: str, top_k: int = 5):\n",
        "        qtokens = self.tokenize_text(query)\n",
        "        results = []\n",
        "        for _, row in self.products_df.iterrows():\n",
        "            searchable = self.tokenize_text(f\"{row['title']} {row['description']}\")\n",
        "            matches = sum(1 for t in qtokens if t in searchable)\n",
        "            if matches > 0:\n",
        "                score = matches + (1 if any(t in str(row['title']).lower() for t in qtokens) else 0)\n",
        "                results.append({'product': row.to_dict(), 'score': score, 'matches': matches})\n",
        "        results.sort(key=lambda x: x['score'], reverse=True)\n",
        "        return results[:top_k]\n",
        "    def evaluate_query(self, query: str, k: int = 3):\n",
        "        results = self.search(query, top_k=k)\n",
        "        retrieved = [r['product']['id'] for r in results]\n",
        "        relevant = self.query_relevance.get(query, set())\n",
        "        p = precision_at_k(relevant, retrieved, k)\n",
        "        r = recall_at_k(relevant, retrieved, k)\n",
        "        return {'query': query, 'retrieved': retrieved, 'relevant': list(relevant), f'precision@{k}': p, f'recall@{k}': r}\n",
        "\n",
        "s = SimpleSearchSystem(df_products)\n",
        "for q in ['iPhone','laptop','shoes']:\n",
        "    print(s.evaluate_query(q, k=3))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Search vs Recommendations\n",
        "\n",
        "| Aspect | Search | Recommendations |\n",
        "|---|---|---|\n",
        "| Trigger | User types a query | System suggests proactively |\n",
        "| Intent | Specific, known | Exploratory, discovery |\n",
        "| Query | Required | None required |\n",
        "| Context | Current session | User history, behavior |\n",
        "| Goal | Find exact/close match | Discover related/new items |\n",
        "| Control | User-driven | System-driven |\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Interview Prep and Key Takeaways\n",
        "\n",
        "- Basic: how search works; search vs recommendations; measuring quality\n",
        "- Technical: typos/normalization; inverted index; ranking signals\n",
        "- Scale: billions of docs; latency budgets; freshness; caching\n",
        "- Business: conversion; A/B tests; internationalization; zero-results handling\n",
        "\n",
        "Key points:\n",
        "- Relevance and latency drive conversion in retail search\n",
        "- Evaluate with P@K, R@K, MRR, NDCG; connect to business metrics\n",
        "- Clean interfaces enable iteration and experiments\n",
        "\n",
        "Next steps: dive into TF-IDF/BM25, query understanding, and learning-to-rank.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Interview Study Guide: What to Know Cold\n",
        "\n",
        "- Core IR concepts\n",
        "  - Inverted index, postings lists, document frequency (DF), term frequency (TF)\n",
        "  - Text processing: tokenization, normalization, stemming vs lemmatization, stopwords, phrase queries\n",
        "  - Query-likelihood vs vector-space models; BM25 intuition vs TF–IDF\n",
        "- Ranking signals and scoring\n",
        "  - Matching features: exact term match, field boosts (title vs description), BM25/TF–IDF\n",
        "  - Business boosts: popularity, freshness, availability, margin, personalization hooks\n",
        "  - Re-ranking: rule-based boosts, learning-to-rank (pointwise/pairwise/listwise)\n",
        "- Query understanding\n",
        "  - Spell correction (edit distance), synonyms, query expansion, entity/attribute detection\n",
        "  - Facets and filters; handling numeric ranges (price), units (inch vs in), categories\n",
        "- Evaluation (offline)\n",
        "  - Precision@K, Recall@K, MAP, MRR, NDCG; graded vs binary relevance\n",
        "  - Labeling strategies: heuristics, click-derived labels, human annotation\n",
        "- Evaluation (online)\n",
        "  - A/B testing basics: metrics (CTR, Conversion, Revenue/Search, Add-to-cart), guardrails (latency, zero-results rate)\n",
        "  - Power, MDE, significance, sample size; experiment length and bucketing\n",
        "- E-commerce specifics\n",
        "  - Query intent (navigational vs informational vs transactional), SKU vs product grouping\n",
        "  - Typos, variants (\"tee\" vs \"t-shirt\"), attribute-aware search (color/size/brand), internationalization\n",
        "  - Merchandising rules, inventory/freshness, cold start, seasonality\n",
        "- System design at a glance\n",
        "  - Indexing pipeline, shards/replicas, caching (Redis), search API (FastAPI), logging/monitoring (latency, p95/p99)\n",
        "  - Backfills, reindexing strategies, blue/green deploys, safety switches\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
